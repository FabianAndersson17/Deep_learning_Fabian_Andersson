{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification code along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nans? False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "raw_data = load_breast_cancer()\n",
    "X, y = raw_data.data, raw_data.target\n",
    "\n",
    "print(f\"Any nans? {np.isnan(X).any()}\")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters 2081\n",
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "\n",
    "def MLP():\n",
    "    model = Sequential(name = \"MLP\")\n",
    "    model.add(InputLayer(X.shape[1], name= \"Input_Layer\"))\n",
    "    model.add(Dense(32, name = \"Hidden1\", activation = \"relu\")) ## Change to he initializer\n",
    "    model.add(Dense(32, name = \"Hidden2\", activation = \"relu\"))\n",
    "    model.add(Dense(1, name = \"Output\", activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\")\n",
    "    return model\n",
    "\n",
    "print(f\"Training parameters {(30+1) * 32+(33*32)+33}\")\n",
    "model = MLP()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 16ms/step - loss: 0.5978 - val_loss: 0.4716\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4194 - val_loss: 0.3521\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3153 - val_loss: 0.2765\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2459 - val_loss: 0.2251\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1971 - val_loss: 0.1906\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1608 - val_loss: 0.1699\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1352 - val_loss: 0.1541\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1157 - val_loss: 0.1428\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1023 - val_loss: 0.1336\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0910 - val_loss: 0.1275\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0825 - val_loss: 0.1223\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0764 - val_loss: 0.1184\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0719 - val_loss: 0.1156\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0672 - val_loss: 0.1125\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0631 - val_loss: 0.1103\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0597 - val_loss: 0.1090\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0564 - val_loss: 0.1072\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0536 - val_loss: 0.1059\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0512 - val_loss: 0.1027\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0485 - val_loss: 0.1009\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0465 - val_loss: 0.0995\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.0991\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0418 - val_loss: 0.0985\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0985\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0384 - val_loss: 0.0982\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0369 - val_loss: 0.0975\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.0973\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0348 - val_loss: 0.0967\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0328 - val_loss: 0.0949\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0316 - val_loss: 0.0941\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0303 - val_loss: 0.0938\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0934\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0925\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0922\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0254 - val_loss: 0.0905\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0908\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0878\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0855\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0858\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.0854\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0873\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0867\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0857\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0858\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0853\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0845\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0827\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0808\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0817\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0820\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0824\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0825\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0819\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0827\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0828\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0837\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0844\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0838\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0845\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0849\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0852\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0848\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0854\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0875\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0913\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0927\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0919\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0939\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0939\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0965\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0988\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0979\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0956\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0965\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.1012\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.1049\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.1050\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.1065\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.1059\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.1055\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.1038\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.1047\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.1060\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.1060\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.1055\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.1058\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.1072\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.1081\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.1081\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.1089\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.1087\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.1090\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.1101\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.1098\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.1101\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.1147\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.1140\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.1163\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.1172\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1179\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.1165\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.1163\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.1158\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.1185\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.1206\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.1191\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.1186\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.1215\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.1222\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.1223\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.1218\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.1229\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.1242\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.1251\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.1268\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.1264\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.1262\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.1250\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.6761e-04 - val_loss: 0.1252\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.5310e-04 - val_loss: 0.1270\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.2071e-04 - val_loss: 0.1260\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.0691e-04 - val_loss: 0.1254\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.0386e-04 - val_loss: 0.1286\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.6352e-04 - val_loss: 0.1275\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.3564e-04 - val_loss: 0.1293\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.1688e-04 - val_loss: 0.1288\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.9970e-04 - val_loss: 0.1292\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.8247e-04 - val_loss: 0.1322\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.6884e-04 - val_loss: 0.1329\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.5921e-04 - val_loss: 0.1304\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.2413e-04 - val_loss: 0.1322\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.1575e-04 - val_loss: 0.1328\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.9172e-04 - val_loss: 0.1331\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8191e-04 - val_loss: 0.1334\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.7323e-04 - val_loss: 0.1348\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.4399e-04 - val_loss: 0.1354\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.3256e-04 - val_loss: 0.1351\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.2409e-04 - val_loss: 0.1365\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.1804e-04 - val_loss: 0.1388\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9871e-04 - val_loss: 0.1386\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.8736e-04 - val_loss: 0.1375\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.7281e-04 - val_loss: 0.1377\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.6185e-04 - val_loss: 0.1395\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.5237e-04 - val_loss: 0.1403\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.4507e-04 - val_loss: 0.1401\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.3605e-04 - val_loss: 0.1406\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.1347e-04 - val_loss: 0.1418\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.0298e-04 - val_loss: 0.1435\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.9820e-04 - val_loss: 0.1419\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.8691e-04 - val_loss: 0.1432\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.7551e-04 - val_loss: 0.1435\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.6752e-04 - val_loss: 0.1436\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.7326e-04 - val_loss: 0.1445\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.6113e-04 - val_loss: 0.1435\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.3996e-04 - val_loss: 0.1435\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.3213e-04 - val_loss: 0.1445\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.3315e-04 - val_loss: 0.1449\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.1845e-04 - val_loss: 0.1465\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.1309e-04 - val_loss: 0.1472\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.9403e-04 - val_loss: 0.1482\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0409e-04 - val_loss: 0.1484\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8786e-04 - val_loss: 0.1483\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.8301e-04 - val_loss: 0.1491\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.7617e-04 - val_loss: 0.1498\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.7020e-04 - val_loss: 0.1508\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.6425e-04 - val_loss: 0.1503\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5634e-04 - val_loss: 0.1513\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.4695e-04 - val_loss: 0.1515\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4490e-04 - val_loss: 0.1519\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3790e-04 - val_loss: 0.1522\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3496e-04 - val_loss: 0.1529\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2779e-04 - val_loss: 0.1526\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2290e-04 - val_loss: 0.1536\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.1849e-04 - val_loss: 0.1543\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.0772e-04 - val_loss: 0.1537\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.1003e-04 - val_loss: 0.1542\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.0478e-04 - val_loss: 0.1557\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9862e-04 - val_loss: 0.1563\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.9485e-04 - val_loss: 0.1560\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8958e-04 - val_loss: 0.1562\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8817e-04 - val_loss: 0.1573\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8022e-04 - val_loss: 0.1573\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7816e-04 - val_loss: 0.1569\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7102e-04 - val_loss: 0.1583\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.7126e-04 - val_loss: 0.1595\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6600e-04 - val_loss: 0.1584\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6153e-04 - val_loss: 0.1607\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5466e-04 - val_loss: 0.1614\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5213e-04 - val_loss: 0.1613\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.4732e-04 - val_loss: 0.1620\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4513e-04 - val_loss: 0.1618\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4365e-04 - val_loss: 0.1636\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3883e-04 - val_loss: 0.1635\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3258e-04 - val_loss: 0.1625\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2967e-04 - val_loss: 0.1632\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2635e-04 - val_loss: 0.1637\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2199e-04 - val_loss: 0.1646\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1974e-04 - val_loss: 0.1654\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1549e-04 - val_loss: 0.1651\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1268e-04 - val_loss: 0.1654\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.0959e-04 - val_loss: 0.1658\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0663e-04 - val_loss: 0.1673\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0442e-04 - val_loss: 0.1675\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0102e-04 - val_loss: 0.1669\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.9949e-04 - val_loss: 0.1674\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9694e-04 - val_loss: 0.1678\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9161e-04 - val_loss: 0.1683\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8942e-04 - val_loss: 0.1691\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8725e-04 - val_loss: 0.1694\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8510e-04 - val_loss: 0.1695\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8295e-04 - val_loss: 0.1693\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8153e-04 - val_loss: 0.1692\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7778e-04 - val_loss: 0.1707\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7631e-04 - val_loss: 0.1721\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7235e-04 - val_loss: 0.1720\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7020e-04 - val_loss: 0.1726\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6777e-04 - val_loss: 0.1727\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6575e-04 - val_loss: 0.1730\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6366e-04 - val_loss: 0.1736\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6185e-04 - val_loss: 0.1736\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6039e-04 - val_loss: 0.1738\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5810e-04 - val_loss: 0.1753\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.5662e-04 - val_loss: 0.1753\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5407e-04 - val_loss: 0.1758\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.5213e-04 - val_loss: 0.1751\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4994e-04 - val_loss: 0.1757\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4750e-04 - val_loss: 0.1761\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4610e-04 - val_loss: 0.1762\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.4606e-04 - val_loss: 0.1772\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4289e-04 - val_loss: 0.1775\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.4263e-04 - val_loss: 0.1786\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4056e-04 - val_loss: 0.1784\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3761e-04 - val_loss: 0.1787\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3550e-04 - val_loss: 0.1789\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3347e-04 - val_loss: 0.1794\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3214e-04 - val_loss: 0.1797\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3028e-04 - val_loss: 0.1801\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2866e-04 - val_loss: 0.1810\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2680e-04 - val_loss: 0.1807\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2587e-04 - val_loss: 0.1807\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2451e-04 - val_loss: 0.1816\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2230e-04 - val_loss: 0.1822\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2120e-04 - val_loss: 0.1826\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2038e-04 - val_loss: 0.1827\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1905e-04 - val_loss: 0.1832\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1651e-04 - val_loss: 0.1837\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1607e-04 - val_loss: 0.1831\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1438e-04 - val_loss: 0.1839\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1294e-04 - val_loss: 0.1849\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1157e-04 - val_loss: 0.1845\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1013e-04 - val_loss: 0.1853\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0888e-04 - val_loss: 0.1857\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0922e-04 - val_loss: 0.1851\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0811e-04 - val_loss: 0.1873\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0706e-04 - val_loss: 0.1876\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0431e-04 - val_loss: 0.1871\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0301e-04 - val_loss: 0.1869\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0208e-04 - val_loss: 0.1871\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0000e-04 - val_loss: 0.1881\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.9272e-05 - val_loss: 0.1884\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.8035e-05 - val_loss: 0.1883\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.7291e-05 - val_loss: 0.1896\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.6214e-05 - val_loss: 0.1891\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.4897e-05 - val_loss: 0.1897\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.3878e-05 - val_loss: 0.1897\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.3063e-05 - val_loss: 0.1895\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.1938e-05 - val_loss: 0.1908\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.0718e-05 - val_loss: 0.1906\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.9605e-05 - val_loss: 0.1907\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.9443e-05 - val_loss: 0.1904\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.7735e-05 - val_loss: 0.1911\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.6804e-05 - val_loss: 0.1921\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.5922e-05 - val_loss: 0.1922\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.5044e-05 - val_loss: 0.1920\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.4266e-05 - val_loss: 0.1932\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.3851e-05 - val_loss: 0.1953\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.2877e-05 - val_loss: 0.1949\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.1187e-05 - val_loss: 0.1936\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.0362e-05 - val_loss: 0.1942\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.0296e-05 - val_loss: 0.1936\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.9436e-05 - val_loss: 0.1961\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.7678e-05 - val_loss: 0.1955\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.6184e-05 - val_loss: 0.1960\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.5756e-05 - val_loss: 0.1968\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.4874e-05 - val_loss: 0.1972\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.3820e-05 - val_loss: 0.1975\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.3051e-05 - val_loss: 0.1987\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.2947e-05 - val_loss: 0.1985\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.2129e-05 - val_loss: 0.1999\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0981e-05 - val_loss: 0.1995\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.9976e-05 - val_loss: 0.1995\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.9243e-05 - val_loss: 0.1992\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.8399e-05 - val_loss: 0.1994\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.7545e-05 - val_loss: 0.1997\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.6934e-05 - val_loss: 0.2001\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.6273e-05 - val_loss: 0.1998\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.5870e-05 - val_loss: 0.1999\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.4992e-05 - val_loss: 0.2004\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.4082e-05 - val_loss: 0.2020\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.3660e-05 - val_loss: 0.2010\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.2829e-05 - val_loss: 0.2009\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.3075e-05 - val_loss: 0.2005\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.2047e-05 - val_loss: 0.2005\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.0746e-05 - val_loss: 0.2015\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.1006e-05 - val_loss: 0.2031\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.9562e-05 - val_loss: 0.2016\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.9502e-05 - val_loss: 0.2008\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.9196e-05 - val_loss: 0.2012\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.8469e-05 - val_loss: 0.2024\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.7283e-05 - val_loss: 0.2028\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7405e-05 - val_loss: 0.2024\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.6865e-05 - val_loss: 0.2050\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.6163e-05 - val_loss: 0.2048\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.5031e-05 - val_loss: 0.2047\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.4416e-05 - val_loss: 0.2045\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.3921e-05 - val_loss: 0.2045\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.3168e-05 - val_loss: 0.2053\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.2782e-05 - val_loss: 0.2056\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.2077e-05 - val_loss: 0.2063\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.1538e-05 - val_loss: 0.2065\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.1077e-05 - val_loss: 0.2065\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.0828e-05 - val_loss: 0.2063\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.9890e-05 - val_loss: 0.2074\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.0184e-05 - val_loss: 0.2070\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.9808e-05 - val_loss: 0.2076\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.8860e-05 - val_loss: 0.2077\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.8071e-05 - val_loss: 0.2081\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.7488e-05 - val_loss: 0.2081\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.7056e-05 - val_loss: 0.2083\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.6583e-05 - val_loss: 0.2089\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.5968e-05 - val_loss: 0.2100\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.5688e-05 - val_loss: 0.2109\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.5227e-05 - val_loss: 0.2107\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4972e-05 - val_loss: 0.2108\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.4295e-05 - val_loss: 0.2108\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.3784e-05 - val_loss: 0.2110\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.3804e-05 - val_loss: 0.2117\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.3414e-05 - val_loss: 0.2114\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.2522e-05 - val_loss: 0.2119\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.2147e-05 - val_loss: 0.2123\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.1806e-05 - val_loss: 0.2120\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.1343e-05 - val_loss: 0.2130\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.1138e-05 - val_loss: 0.2129\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.0489e-05 - val_loss: 0.2128\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0264e-05 - val_loss: 0.2128\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.9844e-05 - val_loss: 0.2132\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.9649e-05 - val_loss: 0.2137\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.8968e-05 - val_loss: 0.2138\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8672e-05 - val_loss: 0.2133\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8561e-05 - val_loss: 0.2141\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.7895e-05 - val_loss: 0.2145\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.7676e-05 - val_loss: 0.2147\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.7411e-05 - val_loss: 0.2142\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.6998e-05 - val_loss: 0.2151\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.6619e-05 - val_loss: 0.2152\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6192e-05 - val_loss: 0.2150\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5844e-05 - val_loss: 0.2155\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5516e-05 - val_loss: 0.2156\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.5256e-05 - val_loss: 0.2160\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4885e-05 - val_loss: 0.2163\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.4551e-05 - val_loss: 0.2165\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4202e-05 - val_loss: 0.2161\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3944e-05 - val_loss: 0.2164\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3535e-05 - val_loss: 0.2169\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3324e-05 - val_loss: 0.2172\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2993e-05 - val_loss: 0.2175\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2734e-05 - val_loss: 0.2180\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2291e-05 - val_loss: 0.2182\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2131e-05 - val_loss: 0.2174\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1766e-05 - val_loss: 0.2176\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.1545e-05 - val_loss: 0.2180\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.1162e-05 - val_loss: 0.2182\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0884e-05 - val_loss: 0.2194\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0632e-05 - val_loss: 0.2198\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.0238e-05 - val_loss: 0.2200\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0029e-05 - val_loss: 0.2198\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.9772e-05 - val_loss: 0.2201\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.9495e-05 - val_loss: 0.2204\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9311e-05 - val_loss: 0.2208\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.9091e-05 - val_loss: 0.2199\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9003e-05 - val_loss: 0.2194\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8581e-05 - val_loss: 0.2207\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8283e-05 - val_loss: 0.2206\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.7914e-05 - val_loss: 0.2207\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7770e-05 - val_loss: 0.2206\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.7640e-05 - val_loss: 0.2215\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7253e-05 - val_loss: 0.2214\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7019e-05 - val_loss: 0.2216\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6720e-05 - val_loss: 0.2227\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6578e-05 - val_loss: 0.2230\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6291e-05 - val_loss: 0.2225\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6026e-05 - val_loss: 0.2228\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5755e-05 - val_loss: 0.2228\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5517e-05 - val_loss: 0.2229\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5324e-05 - val_loss: 0.2234\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5066e-05 - val_loss: 0.2233\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5092e-05 - val_loss: 0.2239\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4684e-05 - val_loss: 0.2236\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4536e-05 - val_loss: 0.2240\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4207e-05 - val_loss: 0.2240\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4047e-05 - val_loss: 0.2241\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3897e-05 - val_loss: 0.2247\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3560e-05 - val_loss: 0.2254\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3421e-05 - val_loss: 0.2255\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3270e-05 - val_loss: 0.2256\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2953e-05 - val_loss: 0.2253\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.2795e-05 - val_loss: 0.2255\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.2662e-05 - val_loss: 0.2256\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2537e-05 - val_loss: 0.2258\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.2264e-05 - val_loss: 0.2259\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1983e-05 - val_loss: 0.2257\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.1779e-05 - val_loss: 0.2262\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 2.1616e-05 - val_loss: 0.2265\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1510e-05 - val_loss: 0.2265\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1666e-05 - val_loss: 0.2283\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.1323e-05 - val_loss: 0.2280\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1031e-05 - val_loss: 0.2273\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0705e-05 - val_loss: 0.2278\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0702e-05 - val_loss: 0.2278\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0463e-05 - val_loss: 0.2292\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.0160e-05 - val_loss: 0.2290\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0028e-05 - val_loss: 0.2288\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9913e-05 - val_loss: 0.2293\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9609e-05 - val_loss: 0.2290\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.9418e-05 - val_loss: 0.2293\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9354e-05 - val_loss: 0.2299\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9124e-05 - val_loss: 0.2299\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.8977e-05 - val_loss: 0.2302\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9280e-05 - val_loss: 0.2298\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8659e-05 - val_loss: 0.2307\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8657e-05 - val_loss: 0.2317\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8427e-05 - val_loss: 0.2318\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.8114e-05 - val_loss: 0.2313\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7949e-05 - val_loss: 0.2310\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.7907e-05 - val_loss: 0.2316\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7767e-05 - val_loss: 0.2322\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7584e-05 - val_loss: 0.2325\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7331e-05 - val_loss: 0.2324\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7254e-05 - val_loss: 0.2321\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7137e-05 - val_loss: 0.2322\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7018e-05 - val_loss: 0.2331\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6816e-05 - val_loss: 0.2334\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6736e-05 - val_loss: 0.2336\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6587e-05 - val_loss: 0.2334\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6492e-05 - val_loss: 0.2341\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6255e-05 - val_loss: 0.2340\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6188e-05 - val_loss: 0.2330\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6102e-05 - val_loss: 0.2326\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.5807e-05 - val_loss: 0.2344\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5745e-05 - val_loss: 0.2347\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.5596e-05 - val_loss: 0.2347\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5459e-05 - val_loss: 0.2349\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.5344e-05 - val_loss: 0.2363\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.5233e-05 - val_loss: 0.2365\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.5052e-05 - val_loss: 0.2363\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.4944e-05 - val_loss: 0.2361\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4783e-05 - val_loss: 0.2363\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4701e-05 - val_loss: 0.2368\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4557e-05 - val_loss: 0.2368\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4457e-05 - val_loss: 0.2379\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4341e-05 - val_loss: 0.2380\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4226e-05 - val_loss: 0.2389\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4047e-05 - val_loss: 0.2384\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.4023e-05 - val_loss: 0.2381\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3797e-05 - val_loss: 0.2392\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3800e-05 - val_loss: 0.2393\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3626e-05 - val_loss: 0.2391\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3463e-05 - val_loss: 0.2390\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3463e-05 - val_loss: 0.2387\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3324e-05 - val_loss: 0.2398\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3180e-05 - val_loss: 0.2400\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3051e-05 - val_loss: 0.2398\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2948e-05 - val_loss: 0.2410\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2900e-05 - val_loss: 0.2410\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2765e-05 - val_loss: 0.2408\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2680e-05 - val_loss: 0.2413\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2484e-05 - val_loss: 0.2408\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2443e-05 - val_loss: 0.2411\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2317e-05 - val_loss: 0.2409\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2220e-05 - val_loss: 0.2415\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2087e-05 - val_loss: 0.2413\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2008e-05 - val_loss: 0.2412\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1900e-05 - val_loss: 0.2415\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1828e-05 - val_loss: 0.2418\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1724e-05 - val_loss: 0.2421\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1649e-05 - val_loss: 0.2426\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1554e-05 - val_loss: 0.2424\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1460e-05 - val_loss: 0.2428\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1340e-05 - val_loss: 0.2434\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1258e-05 - val_loss: 0.2432\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1227e-05 - val_loss: 0.2438\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1104e-05 - val_loss: 0.2435\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1018e-05 - val_loss: 0.2444\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0927e-05 - val_loss: 0.2446\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0836e-05 - val_loss: 0.2443\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0720e-05 - val_loss: 0.2444\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0628e-05 - val_loss: 0.2447\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0619e-05 - val_loss: 0.2445\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0712e-05 - val_loss: 0.2466\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0534e-05 - val_loss: 0.2462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b11f938640>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs = 500, validation_split=.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.597777</td>\n",
       "      <td>0.471621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.419385</td>\n",
       "      <td>0.352064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.315332</td>\n",
       "      <td>0.276482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.245923</td>\n",
       "      <td>0.225104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197143</td>\n",
       "      <td>0.190614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.597777  0.471621\n",
       "1  0.419385  0.352064\n",
       "2  0.315332  0.276482\n",
       "3  0.245923  0.225104\n",
       "4  0.197143  0.190614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_loss = pd.DataFrame(model.history.history)\n",
    "df_loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_loss.plot()\n",
    "## Clear overfittiing as validation loss increases after a certain amount of loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 0.8005 - val_loss: 0.6603\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.5212\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4749 - val_loss: 0.4112\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3651 - val_loss: 0.3176\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2766 - val_loss: 0.2479\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2092 - val_loss: 0.2004\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1642 - val_loss: 0.1704\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1337 - val_loss: 0.1512\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1128 - val_loss: 0.1386\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0977 - val_loss: 0.1303\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0872 - val_loss: 0.1222\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0781 - val_loss: 0.1166\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0714 - val_loss: 0.1126\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0662 - val_loss: 0.1100\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0615 - val_loss: 0.1073\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0580 - val_loss: 0.1047\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0548 - val_loss: 0.1027\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0520 - val_loss: 0.1013\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0496 - val_loss: 0.1002\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0476 - val_loss: 0.0990\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0459 - val_loss: 0.0980\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0438 - val_loss: 0.0965\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.0956\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0955\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0943\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0376 - val_loss: 0.0931\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0362 - val_loss: 0.0927\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0349 - val_loss: 0.0916\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0334 - val_loss: 0.0900\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0325 - val_loss: 0.0892\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0314 - val_loss: 0.0904\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0302 - val_loss: 0.0896\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0904\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0903\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0900\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0892\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0895\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.0899\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0910\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0911\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0886\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0864\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0889\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0904\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0909\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0905\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0899\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0922\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0908\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b120ad5cd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs = 50, validation_split=.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800526</td>\n",
       "      <td>0.660277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.606834</td>\n",
       "      <td>0.521208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474905</td>\n",
       "      <td>0.411246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365070</td>\n",
       "      <td>0.317622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276568</td>\n",
       "      <td>0.247922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.800526  0.660277\n",
       "1  0.606834  0.521208\n",
       "2  0.474905  0.411246\n",
       "3  0.365070  0.317622\n",
       "4  0.276568  0.247922"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss = pd.DataFrame(model.history.history)\n",
    "df_loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b120c5e9d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.fit(scaled_X_train, y_train, epochs = 50, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        43\n",
      "           1       0.97      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXCklEQVR4nO3dfZRdVXnH8e8vk5AhIeSFvHRCEokQRMQGWCmCtDQCSrC0YJcvgKVpi6VWfKloK3YVbGm71NUqpUXQCEhaFEQEAcXENMgCXBYJIQokYGKIeSEwJIEAYWAyM0//uGdgiMm95zD3zj375vdZ66w559xz93kyCQ9773P23ooIzMxSNqzZAZiZDZYTmZklz4nMzJLnRGZmyXMiM7PkDW92AAO1jRkdwyeNa3YYVsDIx7uaHYIV8BI76I6XNZgyTnnH6Ni6rTfXtQ/84uXFETFvMPfLo1SJbPikcUz95/ObHYYVcMg5DzY7BCvgvlg66DK2bOvlvsXTcl07ouNXEwd9wxxKlcjMLAVBb/Q1O4jXcCIzs0IC6KNcL9I7kZlZYX24RmZmCQuCnW5amlnKAuh109LMUuc+MjNLWgC9JZs1x4nMzAorVw+ZE5mZFRSE+8jMLG0RsLNcecyJzMyKEr0Marhm3TmRmVkhAfS5RmZmqXONzMySVnkh1onMzBIWwM4o15ysTmRmVkggeks2ubQTmZkV1hduWppZwtxHZmYtQPS6j8zMUlaZIdaJzMwSFiG6o63ZYbyGE5mZFdbnPjIzS1mls99NSzNLWvk6+8sVjZmVXn9nf56tFknjJN0k6VFJqyQdJ2mCpCWSVmc/x9cqx4nMzArrDeXacrgMWBQRhwGzgVXAhcDSiJgFLM2Oq3LT0swKCcTOGHzqkDQWOAH4M4CI6Aa6JZ0OzM0uWwjcBXymWllOZGZWSB07+2cCTwPfkDQbeAD4BDAlIjZn1zwJTKlVkJuWZlZIkK9ZmTUtJ0paNmA7b0BRw4GjgSsj4ihgB7s0IyMioPYCAa6RmVlhBd7s3xIRc/bw2UZgY0Tclx3fRCWRPSWpIyI2S+oAOmvdxDUyMyskAnpjWK6tejnxJLBB0puyUycBK4HbgPnZufnArbVico3MzAqpdPbXbYjSx4BvStoHWAv8OZUK1o2SzgV+Dby/ViFOZGZWWL3e7I+IFcDump4nFSnHiczMCgnkiRXNLH0ea2lmSausa+lEZmZJ80rjZpa4ynJwnljRzBIWITctzSx9ZZuPzInMzAqpzEfmPjIzS1r5Zoh1IjOzQiqvX7hGZmYJq/NYy7pwIjOzwrxAr5klrTKNj5uWZpY495GZWdIqs1+4aWlmCasMUXIia319wfSLH6Nn/Ag2f+pgxi55mrGLOtmns5u1V7yVvjH+tZfRpKnd/O1l6xk3qQcC7rjuAL539aRmh1VC5auRNTQaSfMkPSZpjaSai2y2inGLn6Z7avsrx12zRvPEhYewc+I+TYzKauntEQsumcp5cw/jE6fN4g//bAszZr3U7LBKqQ/l2oZKwxKZpDbgK8CpwOHAWZIOb9T9yqJtWzejVmznud8/4JVz3QeNomfSyCZGZXls6xzBmodGAdC1o40Na9qZ2LGzyVGVT/9TyzqtNF4XjayRHQOsiYi12QrCNwCnN/B+pTDpuk1sPfNAr0+VuCnTujn4iC4eXT6q2aGUUl8My7UNlUbe6UBgw4Djjdm515B0Xv/inb3P7WhgOI036sHt9O4/nJdn+h9/ytpH9XLRVev46sVTefGFcr3BXgb9c/bn2YZK03udI2IBsABg5BsPrLmicJnt+8sdjF6+nVE/fw7t7GNYVy9TrlzHU399ULNDs5zahgcXXbWOO28ez09+OK7Z4ZRSAD0l6+xvZCLbBEwfcDwtO9eytn5gKls/MBWAfVc9z7g7Op3EkhJc8KUNbFjdzs0L/LSymrI9tWxkIrsfmCVpJpUEdiZwdgPvV1pjF3cy/gedtG3fyYy/X8WO2WN5+kMzmh2W7eItx+zg5Pc9w9qV7Vyx5DEAvvH5Du6/c/8mR1YyQ9xszKNhiSwieiR9FFgMtAHXRMQjjbpf2XS9eQxdbx4DwPZTJrP9lMlNjshqeeRn+3HK1NnNDqP06jmxoqR1wPNAL9ATEXMkTQC+DRwErAPeHxHPVCunofXDiLgjIg6NiIMj4l8beS8zGzp17ux/R0QcGRH9K45fCCyNiFnA0uy4qnI1dM2s9PonVmzgU8vTgYXZ/kLgjFpfaPpTSzNLSyB6+nLXgSZKWjbgeEH2psKrxcGPJAXwteyzKRGxOfv8SWBKrZs4kZlZYQX6yLYMaDLuzu9GxCZJk4Elkh4d+GFERJbkqnIiM7Nion7zkUXEpuxnp6RbqIwIekpSR0RsltQBdNYqx31kZlZIvfrIJI2WNKZ/H3gX8DBwGzA/u2w+cGutmFwjM7PC6lQjmwLcIgkquehbEbFI0v3AjZLOBX4NvL9WQU5kZlZIIHrzd/bvuZyItcBvvLgXEVuBk4qU5URmZoV5pXEzS1rUsbO/XpzIzKywcCIzs7TtRYPGzax1uUZmZkmLgN4+JzIzS5yfWppZ0gI3Lc0see7sN7MWECVbJsiJzMwKc9PSzJJWeWpZrolznMjMrDA3Lc0seW5amlnSAjmRmVn6StaydCIzs4ICwkOUzCx1blqaWfKSeWop6b+o0hSOiI83JCIzK7XUxlouq/KZme2tAkglkUXEwoHHkkZFxIuND8nMyq5sTcua4wwkHSdpJfBodjxb0hUNj8zMSkpEX75tqOQZMPUfwCnAVoCI+DlwQgNjMrOyi5xbDpLaJD0o6fvZ8UxJ90laI+nbkvapVUaukZ8RsWGXU735QjSzlhOVzv48W06fAFYNOP4icGlEHAI8A5xbq4A8iWyDpLcDIWmEpE/vclMz29vUqUYmaRrwB8BV2bGAE4GbsksWAmfUKidPIvswcD5wIPAEcGR2bGZ7LeXcmChp2YDtvF0K+g/g74C+7PgA4NmI6MmON1LJPVXVfCE2IrYAH6x1nZntRfpqX5LZEhFzdveBpNOAzoh4QNLcwYST56nlGyXdLulpSZ2SbpX0xsHc1MwS1v8eWZ6tuuOBP5K0DriBSpPyMmCcpP5K1jRgU62C8jQtvwXcCHQAU4HvANfn+J6ZtaiIfFv1MuKzETEtIg4CzgTujIgPAj8G3ptdNh+4tVY8eRLZqIj4n4joybbrgPYc3zOzVlXH1y924zPABZLWUOkzu7rWF6qNtZyQ7f5Q0oVUqn4BfAC443WHaGbpq/MQpYi4C7gr218LHFPk+9U6+x+gkrj6I/6rgfcFPlvkRmbWOlSyIUrVxlrOHMpAzCwRIUhxYkVJRwCHM6BvLCL+u1FBmVnJpVIj6yfpc8BcKonsDuBU4F7Aicxsb1WyRJbnqeV7gZOAJyPiz4HZwNiGRmVm5dbYp5aF5WladkVEn6QeSfsDncD0BsdlZmWV0sSKAyyTNA74OpUnmS8AP21kUGZWbsk8tewXER/Jdr8qaRGwf0T8orFhmVmppZLIJB1d7bOIWN6YkMys7FKqkX2pymdBZYBnXY18vItDznmw3sVaAy1+YkWzQ7ACjjmlTstupNJHFhHvGMpAzCwRQ/xEMg8v0GtmxTmRmVnqlH9ixSHhRGZmxZWsRpZnhlhJ+hNJF2fHMyQVmmLDzFqHIv82VPIMUboCOA44Kzt+HvhKwyIys/Krz1TXdZOnafm2iDha0oMAEfFMngUzzayFlaxpmSeR7ZTURha6pEkUWUPFzFpOSi/E9vtP4BZgsqR/pTIbxj80NCozK69I8KllRHxT0gNUpvIRcEZEeKVxs71ZajUySTOAF4HbB56LiPWNDMzMSiy1RAb8gFcXIWkHZgKPAW9pYFxmVmLJ9ZFFxFsHHmezYnxkD5ebmQ25wm/2R8RySW9rRDBmlojUamSSLhhwOAw4GniiYRGZWbnV6amlpHbgbmAklVx0U0R8TtJMKguCH0BlVupzIqK7Wll53uwfM2AbSaXP7PTXH76ZJa8+i4+8DJwYEbOBI4F5ko4FvghcGhGHAM8A59YqqGqNLHsRdkxEfLpmSGa2VxD16eyPiKCyBgjAiGzrn7T17Oz8QuAfgSurlbXHGpmk4RHRCxw/yHjNrNXkr5FNlLRswHbewGIktUlaQWV1tiXAr4BnI6Inu2QjcGCtcKrVyH5GpT9shaTbgO8AO175c0TcXKtwM2tBxWa22BIRc/ZYVKWydGS2UtstwGGvJ6Q8Ty3bga1Uqnv975MF4ERmtreq8xCliHhW0o+pzLQzLmsR9gDTgE21vl8tkU3Onlg+zKsJ7JX7DiJmM0tcPfrIsgkodmZJbF/gnVQ6+n9MZUz3DcB84NZaZVVLZG3Afrw2gfVzIjPbm9UnA3QAC7OHisOAGyPi+5JWAjdI+hfgQeDqWgVVS2SbI+KSuoRrZq2jTqsoZQt9H7Wb82uBQrNQV0tk5Vq4zsxKI6WxlicNWRRmlpZUEllEbBvKQMwsHclNrGhm9hpeadzMUifK14HuRGZmxblGZmapS+mppZnZ7jmRmVnSUlwOzszsN7hGZmapcx+ZmaXPiczMUucamZmlLaj7xIqD5URmZoXUa/GRenIiM7PinMjMLHWKcmUyJzIzK8azX5hZK3AfmZklz0OUzCx9rpGZWdKKrTQ+JJzIzKy4kiWyYc0OwMzS0v9CbJ6tajnSdEk/lrRS0iOSPpGdnyBpiaTV2c/xtWJyIjOzwtQXubYaeoBPRcThwLHA+ZIOBy4ElkbELGBpdlyVE5mZFRMFtmrFRGyOiOXZ/vPAKuBA4HRgYXbZQuCMWiG5j6xBJk3t5m8vW8+4ST0QcMd1B/C9qyc1OyzbjRe2t3Hpp6ez7tF2JLjgy+sZuW8f/3XhdLp2DGPKtG4+85VfM3pMyd45aKICr19MlLRswPGCiFjwG+VJBwFHAfcBUyJic/bRk8CUWjdpWCKTdA1wGtAZEUc06j5l1dsjFlwylTUPjWLf0b1cvuiXLL97DOtXtzc7NNvFlRcfyJy5z3HR19exs1u83DWMz555MH958SZ++7gdLL5+AjddOZn5f/dks0Mtj/yd/VsiYk61CyTtB3wX+JuIeE56dbG5iAip9jPSRjYtrwXmNbD8UtvWOYI1D40CoGtHGxvWtDOxY2eTo7Jd7XhuGA/932jmnb0NgBH7BPuN7WXj2pG89dgdABx1wvPc+4NxTYyyfOrR2Q8gaQSVJPbNiLg5O/2UpI7s8w6gs1Y5DUtkEXE3sK1R5adkyrRuDj6ii0eXj2p2KLaLJ9ePZOwBPXzpkzP4yDsP5dJPTeelF4fxhkNf4qeLxgJwz/fH8fQTI5ocaYkEEJFvq0KVqtfVwKqI+PKAj24D5mf784Fba4XU9M5+SedJWiZp2U5ebnY4ddc+qpeLrlrHVy+eyosvtDU7HNtFby+seWgUp/3pFq5Y8kvaR/Xx7csnc8GX13P7wgM4/5RD6XphGMP3KdmLU02mvnxbDccD5wAnSlqRbe8GvgC8U9Jq4OTsuKqmd/ZnHX8LAPbXhJb619I2PLjoqnXcefN4fvLDcc0Ox3ZjYsdOJnXs5LCjXwTgd097lhsvr/SHff6GtQBs/NVI7lu6fzPDLJV6TawYEfdmxe3OSUXKanqNrHUFF3xpAxtWt3PzAj+tLKsJk3uYOLWbDWtGArDinjHMmPUyz26p/D++rw++ddkUTjtnazPDLJe8zcohnLOs6TWyVvWWY3Zw8vueYe3Kdq5Y8hgA3/h8B/ff6f+zl835/7KJL370DfTsFL81o5tPXbqe/71pPLdfOxGA40/dzrvOdHfvQHvNWEtJ1wNzqbxHshH4XERc3aj7lc0jP9uPU6bObnYYlsPBR3Rx+aJfvubcez60hfd8aEuTIkrA3pLIIuKsRpVtZs2119TIzKxFBdBbrkzmRGZmhblGZmbp8ypKZpY618jMLG1eDs7MUidA7uw3s9R5pXEzS5ublmaWvqEdR5mHE5mZFeanlmaWPtfIzCxp4aeWZtYKypXHnMjMrDi/fmFm6XMiM7OkBVCytYqdyMysEBFuWppZC+grV5XMiczMinHT0sxaQdmall7X0syKq9O6lpKukdQp6eEB5yZIWiJpdfZzfK1ynMjMrKC6LtB7LTBvl3MXAksjYhawNDuuyonMzIrpX0Upz1arqIi7gV1XPz4dWJjtLwTOqFWO+8jMrLACfWQTJS0bcLwgIhbU+M6UiNic7T8JTKl1EycyMysufyLbEhFzXv9tIqTakwa5aWlmxQTQF/m21+cpSR0A2c/OWl9wIjOzgura2b87twHzs/35wK21vuBEZmbF1e/1i+uBnwJvkrRR0rnAF4B3SloNnJwdV+U+MjMrJoDe+rzaHxFn7eGjk4qU40RmZgUFRLnGKDmRmVlxJRui5ERmZsX0P7UsEScyMyvONTIzS54TmZklLQJ6e5sdxWs4kZlZca6RmVnynMjMLG2DGkfZEE5kZlZMQPiFWDNLXp2GKNWLE5mZFRPh5eDMrAW4s9/MUheukZlZ2gY1aWJDOJGZWTEeNG5mqQsgPETJzJIWnljRzFpAuGlpZskrWY1MUaKnD5KeBn7d7DgaYCKwpdlBWCGt+nf2hoiYNJgCJC2i8vvJY0tEzBvM/fIoVSJrVZKWDWa1ZRt6/jtLi9e1NLPkOZGZWfKcyIbGgmYHYIX57ywh7iMzs+S5RmZmyXMiM7PkOZE1kKR5kh6TtEbShc2Ox2qTdI2kTkkPNzsWy8+JrEEktQFfAU4FDgfOknR4c6OyHK4FGv4Cp9WXE1njHAOsiYi1EdEN3ACc3uSYrIaIuBvY1uw4rBgnssY5ENgw4Hhjds7M6syJzMyS50TWOJuA6QOOp2XnzKzOnMga535glqSZkvYBzgRua3JMZi3JiaxBIqIH+CiwGFgF3BgRjzQ3KqtF0vXAT4E3Sdoo6dxmx2S1eYiSmSXPNTIzS54TmZklz4nMzJLnRGZmyXMiM7PkOZElRFKvpBWSHpb0HUmjBlHWtZLem+1fVW1Au6S5kt7+Ou6xTtJvrLazp/O7XPNCwXv9o6RPF43RWoMTWVq6IuLIiDgC6AY+PPBDSa9rndKI+FBErKxyyVygcCIzGypOZOm6Bzgkqy3dI+k2YKWkNkn/Jul+Sb+Q9FcAqrg8mx/tf4HJ/QVJukvSnGx/nqTlkn4uaamkg6gkzE9mtcHfkzRJ0neze9wv6fjsuwdI+pGkRyRdBajWH0LS9yQ9kH3nvF0+uzQ7v1TSpOzcwZIWZd+5R9JhdfltWtK80niCsprXqcCi7NTRwBER8XiWDLZHxO9IGgn8RNKPgKOAN1GZG20KsBK4ZpdyJwFfB07IypoQEdskfRV4ISL+PbvuW8ClEXGvpBlURi+8GfgccG9EXCLpD4A8b8X/RXaPfYH7JX03IrYCo4FlEfFJSRdnZX+UyqIgH46I1ZLeBlwBnPg6fo3WQpzI0rKvpBXZ/j3A1VSafD+LiMez8+8Cfru//wsYC8wCTgCuj4he4AlJd+6m/GOBu/vLiog9zct1MnC49EqFa39J+2X3+OPsuz+Q9EyOP9PHJb0n25+exboV6AO+nZ2/Drg5u8fbge8MuPfIHPewFudElpauiDhy4InsP+gdA08BH4uIxbtc9+46xjEMODYiXtpNLLlJmkslKR4XES9Kugto38Plkd332V1/B2buI2s9i4G/ljQCQNKhkkYDdwMfyPrQOoB37Oa7/wecIGlm9t0J2fnngTEDrvsR8LH+A0lHZrt3A2dn504FxteIdSzwTJbEDqNSI+w3DOivVZ5Npcn6HPC4pPdl95Ck2TXuYXsBJ7LWcxWV/q/l2QIaX6NS874FWJ199t9UZnh4jYh4GjiPSjPu57zatLsdeE9/Zz/wcWBO9jBhJa8+Pf0nKonwESpNzPU1Yl0EDJe0CvgClUTabwdwTPZnOBG4JDv/QeDcLL5H8PThhme/MLMW4BqZmSXPiczMkudEZmbJcyIzs+Q5kZlZ8pzIzCx5TmRmlrz/BxV/GpDxbQQyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "y_pred = (y_pred > 0.5)*1\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d2a78ac298b5ae80b85cde5c5120964961c13bf12476239ce8f38bfa9084b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Deep_learning_Fabian_Andersson-5nGO-T3z')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
